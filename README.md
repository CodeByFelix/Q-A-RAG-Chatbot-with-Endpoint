## RAG Q&A Chatbot ğŸ¤–

This project is a Retrieval-Augmented Generation (RAG) based Q&A chatbot built using LangGraph, ChromaDB, and FastAPI.
It leverages vector search for document retrieval, OpenAI models for response generation, and MongoDB for short-term memory storage.

The chatbot is exposed via REST APIs that support both single-response requests and streaming responses.

### ğŸš€ Features

 - ğŸ” RAG with LangGraph â€“ Combines LLM reasoning with vector search.

 - ğŸ“‚ Chroma Cloud Integration â€“ Persistent vector storage using ChromaDB.

 - ğŸ§  Short-Term Memory â€“ Powered by MongoDB for conversation persistence.

 - âš¡ FastAPI Endpoints â€“ REST APIs for synchronous and streaming responses.

 - ğŸ”‘ Environment Variables â€“ Securely configured via .env file.

### ğŸ“‚ Project Structure

```bash
â”œâ”€â”€ PDF/                     # Folder containing source PDF files
â”œâ”€â”€ src/                     # Core project source code
â”‚   â”œâ”€â”€ __init__.py          # Marks the src directory as a package
â”‚   â”œâ”€â”€ RAG.py               # LangGraph RAG agent logic
â”‚   â”œâ”€â”€ router.py            # FastAPI routes for chat & streaming
â”‚   â”œâ”€â”€ utils.py             # Utility functions (DB, memory, helpers)
â”œâ”€â”€ .env                     # Environment variables (API keys, DB URLs)
â”œâ”€â”€ embedding.ipynb          # Jupyter Notebook for PDF data ingestion & embeddings
â”œâ”€â”€ main.py                  # Entry point to run the FastAPI application
â””â”€â”€ requirements.txt         # Python dependencies
```

### âš™ï¸ Environment Variables

Create a .env file in the root directory and set the following:
```env
CHROMA_API_KEY = your_chroma_api_key
CHROMA_TENANT = your_chroma_tenant
OPENAI_API_KEY = your_openai_api_key
MONGODB_URL = your_mongodb_connection_url
```

### ğŸ› ï¸ Installation & Setup

#### 1. Clone the Repository

```bash
git clone https://github.com/CodeByFelix/Q-A-RAG-Chatbot-with-Endpoint.git
cd Q-A-RAG-Chatbot-with-Endpoint
```


#### 2. Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate   # For Linux/Mac
venv\Scripts\activate      # For Windows
```


#### 3. Install Dependencies

```bash
pip install -r requirements.txt
```


#### 4. Run the App

```bash
uvicorn main:app --reload
```

### ğŸ“¡ API Endpoints

#### 1. Get Chat Response

##### Endpoint:
```http
POST /chat/chat_response
```

##### Request Body:
```json
{
  "message": "What is LangGraph?",
  "thread_id": "1234"
}
```

##### Response:
```json
{
  "message": "LangGraph is a framework for building LLM-powered agents..."
}
```

#### 2. Get Streaming Response

##### Endpoint:
```http
POST /stream_response
```

##### Request Body:
```json
{
  "message": "Explain RAG in detail",
  "thread_id": "1234"
}
```

##### Response:

 - Returns a streaming text/plain response.


### ğŸ§© Tech Stack

 - LangGraph
 â€“ Agent orchestration

 - ChromaDB
 â€“ Vector database (Cloud Deployment)

 - FastAPI
 â€“ API framework

 - MongoDB
 â€“ Persistent memory storage

 - OpenAI
 â€“ LLM for response generation

 